"""
Test suite for the main training loop and integration.

Tests the full training pipeline including data loading, model training,
checkpointing, and metrics logging.
"""
import sys
import os
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

import json
import tempfile
import time
from pathlib import Path
from unittest.mock import MagicMock, patch, PropertyMock, call, mock_open

import torch
import torch.nn as nn
import pytest
import numpy as np

from train import train, main, LogLevelEnum
from batch_metrics import BatchMetrics


class TestTrainFunction:
    """Test suite for the main train function."""
    
    @pytest.fixture
    def mock_model(self):
        """Create a mock model for training."""
        model = MagicMock()
        model.train = MagicMock()
        
        # Create mock parameter with device attribute
        mock_param = MagicMock()
        mock_param.device = torch.device('cpu')
        model.parameters = MagicMock(return_value=iter([mock_param]))  # Return iterator
        
        # Mock model forward pass
        output = MagicMock()
        output.loss = torch.tensor(2.5, requires_grad=True)
        model.return_value = output
        
        return model
    
    @pytest.fixture
    def mock_optimizer(self):
        """Create a mock optimizer."""
        optimizer = MagicMock()
        optimizer.step = MagicMock()
        optimizer.zero_grad = MagicMock()
        return optimizer
    
    @pytest.fixture
    def mock_scheduler(self):
        """Create a mock scheduler."""
        scheduler = MagicMock()
        scheduler.step = MagicMock()
        scheduler.get_last_lr = MagicMock(return_value=[1e-5])
        return scheduler
    
    @pytest.fixture
    def mock_data_loader(self):
        """Create a mock data loader that produces minibatches."""
        # Create mock minibatch data
        minibatch = {
            'input_ids': torch.tensor([[1, 2, 3, 4, 5]]),
            'labels': torch.tensor([[10, 20, 30, 40, 50]]),
            'position_ids': torch.tensor([[0, 1, 2, 3, 4]]),
            'num_loss_counted_tokens': 5,
            'num_samples': 1,
            'batch_num_loss_counted_tokens': 5
        }
        
        # Create a data loader that yields batches (which are lists of minibatches)
        def data_generator():
            for _ in range(3):  # Yield 3 batches
                yield [minibatch.copy(), minibatch.copy()]  # 2 minibatches per batch
        
        loader = MagicMock()
        loader.__iter__ = data_generator
        return loader
    
    @patch.dict(os.environ, {'WORLD_SIZE': '2', 'RANK': '0'})
    @patch('torch.distributed.is_initialized', return_value=True)
    @patch('torch.distributed.get_world_size', return_value=2)
    @patch('torch.distributed.get_rank', return_value=0)
    @patch('torch.distributed.all_reduce')
    @patch('train.dist.get_rank', return_value=0)
    @patch('train.AsyncStructuredLogger')
    @patch('train.take_gradient_step')
    @patch('train.save_model')
    @patch('torch.cuda.reset_peak_memory_stats')
    @patch('torch.cuda.empty_cache')
    @patch('torch.cuda.max_memory_allocated', return_value=1e9)
    @patch('torch.distributed.barrier')
    def test_train_basic_loop(self, mock_barrier, mock_memory, mock_empty_cache,
                              mock_reset_stats, mock_save, mock_grad_step,
                              mock_logger_cls, mock_dist_rank, mock_all_reduce, mock_torch_rank,
                              mock_world_size, mock_is_init,
                              mock_model, mock_optimizer, mock_scheduler, mock_data_loader):
        """Test basic training loop execution."""
        # Setup mocks
        mock_logger = MagicMock()
        mock_logger_cls.return_value = mock_logger
        
        mock_grad_step.return_value = torch.tensor(1.0)
        
        with tempfile.TemporaryDirectory() as temp_dir:
            # Run training for a few steps
            with patch('train.iter', side_effect=lambda x: iter(x)):
                # Limit iterations by making data_loader finite
                mock_data_loader.__iter__ = lambda self: iter([
                    [{'input_ids': torch.tensor([[1, 2]]),
                      'labels': torch.tensor([[10, 20]]),
                      'num_loss_counted_tokens': 2,
                      'num_samples': 1,
                      'batch_num_loss_counted_tokens': 2}]
                    for _ in range(2)
                ])
                
                train(
                    model=mock_model,
                    optimizer=mock_optimizer,
                    lr_scheduler=mock_scheduler,
                    data_loader=mock_data_loader,
                    output_dir=temp_dir,
                    min_samples_per_checkpoint=10,
                    model_name_or_path="test/model"
                )
        
        # Verify model was set to training mode
        mock_model.train.assert_called_once()
        
        # Verify gradient steps were taken
        assert mock_grad_step.call_count >= 1
        
        # Verify metrics were logged
        assert mock_logger.log_sync.call_count >= 1
    
    @patch.dict(os.environ, {'WORLD_SIZE': '2', 'RANK': '0'})
    @patch('torch.distributed.is_initialized', return_value=True)
    @patch('torch.distributed.get_world_size', return_value=2)
    @patch('torch.distributed.get_rank', return_value=0)
    @patch('torch.distributed.all_reduce')
    @patch('train.dist.get_rank', return_value=0)
    @patch('train.AsyncStructuredLogger')
    @patch('train.take_gradient_step')
    @patch('train.save_model')
    @patch('torch.cuda.reset_peak_memory_stats')
    @patch('torch.cuda.empty_cache')
    @patch('torch.distributed.barrier')
    def test_train_checkpoint_saving(self, mock_barrier, mock_empty_cache,
                                    mock_reset_stats, mock_save, mock_grad_step,
                                    mock_logger_cls, mock_dist_rank, mock_all_reduce, mock_torch_rank,
                                    mock_world_size, mock_is_init,
                                    mock_model, mock_optimizer, mock_scheduler):
        """Test checkpoint saving based on samples processed."""
        mock_logger = MagicMock()
        mock_logger_cls.return_value = mock_logger
        mock_grad_step.return_value = torch.tensor(1.0)
        
        # Create data loader with enough samples to trigger checkpoint
        batches = []
        for _ in range(5):
            batch = [{
                'input_ids': torch.tensor([[1, 2, 3]]),
                'labels': torch.tensor([[10, 20, 30]]),
                'num_loss_counted_tokens': 3,
                'num_samples': 3,  # 3 samples per batch
                'batch_num_loss_counted_tokens': 3
            }]
            batches.append(batch)
        
        mock_data_loader = MagicMock()
        mock_data_loader.__iter__ = lambda self: iter(batches)
        
        with tempfile.TemporaryDirectory() as temp_dir:
            train(
                model=mock_model,
                optimizer=mock_optimizer,
                lr_scheduler=mock_scheduler,
                data_loader=mock_data_loader,
                output_dir=temp_dir,
                min_samples_per_checkpoint=10,  # Save after 10 samples
                model_name_or_path="test/model"
            )
        
        # Should save checkpoint when samples exceed threshold
        assert mock_save.call_count >= 1
        
        # Check that save was called with correct arguments
        save_call = mock_save.call_args_list[0]
        assert save_call[0][0] == mock_model
        assert save_call[0][1] >= 10  # samples_seen
    
    @patch.dict(os.environ, {'WORLD_SIZE': '4', 'RANK': '1'})
    @patch('torch.distributed.is_initialized', return_value=True)
    @patch('torch.distributed.get_world_size', return_value=4)
    @patch('torch.distributed.get_rank', return_value=1)
    @patch('torch.distributed.all_reduce')
    @patch('train.dist.get_rank', return_value=1)
    @patch('train.AsyncStructuredLogger')
    @patch('train.take_gradient_step')
    @patch('torch.cuda.reset_peak_memory_stats')
    @patch('torch.cuda.empty_cache')
    @patch('torch.distributed.barrier')
    def test_train_non_main_process(self, mock_barrier, mock_empty_cache, mock_reset_stats, mock_grad_step,
                                   mock_logger_cls, mock_dist_rank, mock_all_reduce, mock_torch_rank,
                                   mock_world_size, mock_is_init,
                                   mock_model, mock_optimizer, mock_scheduler):
        """Test training on non-main process (rank != 0)."""
        mock_logger = MagicMock()
        mock_logger_cls.return_value = mock_logger
        mock_grad_step.return_value = torch.tensor(1.0)
        
        # Simple data loader
        mock_data_loader = MagicMock()
        mock_data_loader.__iter__ = lambda self: iter([[{
            'input_ids': torch.tensor([[1, 2]]),
            'labels': torch.tensor([[10, 20]]),
            'num_loss_counted_tokens': 2,
            'num_samples': 1,
            'batch_num_loss_counted_tokens': 2
        }]])
        
        with tempfile.TemporaryDirectory() as temp_dir:
            train(
                model=mock_model,
                optimizer=mock_optimizer,
                lr_scheduler=mock_scheduler,
                data_loader=mock_data_loader,
                output_dir=temp_dir,
                min_samples_per_checkpoint=100,
                model_name_or_path="test/model"
            )
        
        # Non-main process should still train
        mock_model.train.assert_called_once()
        
        # But shouldn't log metrics (only rank 0 logs in the if statement)
        # The logger is created but log_sync is only called if is_main_process
        if mock_logger.log_sync.called:
            # If it was called, verify it was not for metrics logging
            for call_args in mock_logger.log_sync.call_args_list:
                # This would be empty or different for non-main process
                pass


class TestMainCLI:
    """Test suite for the main CLI function."""
    
    @patch('train.init_distributed_environment')
    @patch('train.setup_logger')
    @patch('train.setup_model')
    @patch('train.setup_training_components')
    @patch('train.get_data_loader')
    @patch('train.train')
    @patch('train.dist.get_rank', return_value=0)
    @patch.dict(os.environ, {'WORLD_SIZE': '1'})
    def test_main_basic(self, mock_rank, mock_train_fn, mock_get_loader,
                        mock_setup_components, mock_setup_model,
                        mock_setup_logger, mock_init_dist):
        """Test basic main function execution."""
        # Setup mocks
        mock_model = MagicMock()
        mock_setup_model.return_value = mock_model
        
        mock_optimizer = MagicMock()
        mock_scheduler = MagicMock()
        mock_setup_components.return_value = (mock_model, mock_optimizer, mock_scheduler)
        
        mock_loader = MagicMock()
        mock_get_loader.return_value = mock_loader
        
        with tempfile.TemporaryDirectory() as temp_dir:
            main(
                model_name_or_path="test/model",
                data_path="test.jsonl",
                batch_size=32,
                max_tokens_per_gpu=1000,
                learning_rate=1e-5,
                num_warmup_steps=10,
                lr_scheduler="constant",
                seed=42,
                use_liger_kernels=False,
                orthogonal_subspace_learning=False,
                output_dir=temp_dir,
                logging_level=LogLevelEnum.INFO,
                min_samples_per_checkpoint=1000
            )
        
        # Verify initialization
        mock_init_dist.assert_called_once()
        mock_setup_logger.assert_called_once_with(level="INFO")
        
        # Verify model setup
        mock_setup_model.assert_called_once()
        mock_setup_components.assert_called_once()
        
        # Verify data loader creation
        mock_get_loader.assert_called_once()
        
        # Verify training was started
        mock_train_fn.assert_called_once()
    
    @patch('train.init_distributed_environment')
    @patch('train.setup_logger')
    @patch('train.setup_model')
    @patch('train.setup_training_components')
    @patch('train.get_data_loader')
    @patch('train.train')
    @patch('train.dist.get_rank', return_value=0)
    @patch.dict(os.environ, {'WORLD_SIZE': '1'})
    @patch('builtins.open', new_callable=mock_open)
    def test_main_saves_parameters(self, mock_file, mock_rank, mock_train_fn,
                                  mock_get_loader, mock_setup_components,
                                  mock_setup_model, mock_setup_logger, mock_init_dist):
        """Test that main saves training parameters."""
        mock_model = MagicMock()
        mock_setup_model.return_value = mock_model
        mock_setup_components.return_value = (mock_model, MagicMock(), MagicMock())
        mock_get_loader.return_value = MagicMock()
        
        with tempfile.TemporaryDirectory() as temp_dir:
            main(
                model_name_or_path="test/model",
                data_path="test.jsonl",
                batch_size=32,
                max_tokens_per_gpu=1000,
                learning_rate=1e-5,
                num_warmup_steps=10,
                lr_scheduler="constant",
                seed=42,
                use_liger_kernels=True,
                orthogonal_subspace_learning=True,
                output_dir=temp_dir,
                logging_level=LogLevelEnum.DEBUG,
                min_samples_per_checkpoint=500
            )
        
        # Check that parameters were saved
        mock_file.assert_called()
        
        # Extract what was written
        written_content = ''.join(call.args[0] for call in mock_file().write.call_args_list)
        if written_content:
            params = json.loads(written_content)
            assert params['model_name_or_path'] == "test/model"
            assert params['batch_size'] == 32
            assert params['learning_rate'] == 1e-5
            assert params['use_liger_kernels'] == True
            assert params['orthogonal_subspace_learning'] == True
    
    @patch('train.init_distributed_environment')
    @patch('train.dist.get_rank', return_value=1)
    @patch.dict(os.environ, {'WORLD_SIZE': '2'})
    def test_main_non_rank_0_no_params_save(self, mock_rank, mock_init_dist):
        """Test that non-rank-0 processes don't save parameters."""
        with patch('builtins.open', new_callable=mock_open) as mock_file:
            with patch('train.setup_logger'):
                with patch('train.setup_model') as mock_setup_model:
                    with patch('train.setup_training_components') as mock_setup_comp:
                        with patch('train.get_data_loader'):
                            with patch('train.train'):
                                mock_setup_model.return_value = MagicMock()
                                mock_setup_comp.return_value = (MagicMock(), MagicMock(), MagicMock())
                                
                                with tempfile.TemporaryDirectory() as temp_dir:
                                    main(
                                        model_name_or_path="test/model",
                                        data_path="test.jsonl",
                                        batch_size=32,
                                        max_tokens_per_gpu=1000,
                                        learning_rate=1e-5,
                                        num_warmup_steps=10,
                                        lr_scheduler="constant",
                                        seed=42,
                                        use_liger_kernels=False,
                                        orthogonal_subspace_learning=False,
                                        output_dir=temp_dir,
                                        logging_level=LogLevelEnum.INFO,
                                        min_samples_per_checkpoint=1000
                                    )
                                
                                # Check that open was not called for writing params
                                # (it might be called for other purposes)
                                param_file_written = any(
                                    'training_params.json' in str(call)
                                    for call in mock_file.call_args_list
                                )
                                assert not param_file_written


class TestBatchProcessing:
    """Test suite for batch processing within training loop."""
    
    def test_minibatch_accumulation(self):
        """Test accumulation of metrics across minibatches."""
        batch_metrics = BatchMetrics()
        
        # Simulate processing 3 minibatches in a batch
        minibatches = [
            {'num_samples': 2, 'loss': 2.5, 'tokens': 100},
            {'num_samples': 3, 'loss': 3.0, 'tokens': 150},
            {'num_samples': 1, 'loss': 1.5, 'tokens': 50}
        ]
        
        for mb in minibatches:
            batch_metrics.accumulate_minibatch_metrics(
                num_samples=mb['num_samples'],
                loss=mb['loss'],
                num_total_tokens=mb['tokens']
            )
        
        # Check accumulated values
        assert batch_metrics.minibatch_metrics['num_samples'] == 6
        assert batch_metrics.minibatch_metrics['loss'] == 7.0
        assert batch_metrics.minibatch_metrics['num_total_tokens'] == 300
    
    @patch('torch.distributed.all_reduce')
    def test_batch_reduction_across_ranks(self, mock_all_reduce):
        """Test reduction of batch metrics across distributed ranks."""
        batch_metrics = BatchMetrics()
        
        # Setup metrics
        batch_metrics.minibatch_metrics['num_samples'] = 4
        batch_metrics.minibatch_metrics['loss'] = 10.0
        
        # Mock all_reduce to simulate 4 GPUs
        def all_reduce_effect(tensor, op):
            tensor.mul_(4)
        mock_all_reduce.side_effect = all_reduce_effect
        
        device = torch.device('cpu')
        batch_metrics.reduce_batch_metrics(device)
        
        # Check reduced totals
        assert batch_metrics.totals['num_samples'] == 16
        assert batch_metrics.totals['loss'] == 40.0
        
        # Check minibatch metrics were cleared
        assert len(batch_metrics.minibatch_metrics) == 0


class TestErrorHandling:
    """Test suite for error handling in training."""
    
    @patch.dict(os.environ, {'WORLD_SIZE': '1', 'RANK': '0'})
    @patch('torch.distributed.is_initialized', return_value=True)
    @patch('torch.distributed.get_world_size', return_value=1)
    @patch('torch.distributed.get_rank', return_value=0)
    @patch('torch.distributed.all_reduce')
    @patch('train.dist.get_rank', return_value=0)
    @patch('train.AsyncStructuredLogger')
    @patch('torch.cuda.reset_peak_memory_stats')
    @patch('torch.cuda.empty_cache')
    @patch('torch.distributed.barrier')
    def test_train_handles_empty_batch(self, mock_barrier, mock_empty_cache, mock_reset_stats,
                                       mock_logger_cls, mock_dist_rank, mock_all_reduce,
                                       mock_torch_rank, mock_world_size, mock_is_init):
        """Test handling of batches with minimal data."""
        mock_model = MagicMock()
        mock_model.train = MagicMock()
        mock_param = MagicMock()
        mock_param.device = torch.device('cpu')
        mock_model.parameters = MagicMock(return_value=iter([mock_param]))
        
        # Mock model output
        output = MagicMock()
        output.loss = torch.tensor(2.5, requires_grad=True)
        mock_model.return_value = output
        
        # Data loader with minimal batch
        mock_data_loader = MagicMock()
        mock_data_loader.__iter__ = lambda self: iter([
            [{'input_ids': torch.tensor([[1]]),
              'labels': torch.tensor([[10]]),
              'num_loss_counted_tokens': 1,
              'num_samples': 1,
              'batch_num_loss_counted_tokens': 1}]
        ])
        
        mock_optimizer = MagicMock()
        mock_scheduler = MagicMock()
        
        with tempfile.TemporaryDirectory() as temp_dir:
            # Should handle minimal batch without crashing
            with patch('train.take_gradient_step') as mock_grad_step:
                mock_grad_step.return_value = torch.tensor(1.0)
                
                train(
                    model=mock_model,
                    optimizer=mock_optimizer,
                    lr_scheduler=mock_scheduler,
                    data_loader=mock_data_loader,
                    output_dir=temp_dir,
                    min_samples_per_checkpoint=100,
                    model_name_or_path="test/model"
                )
                
                # Should have processed one batch
                assert mock_grad_step.call_count == 1


class TestMemoryManagement:
    """Test suite for memory management during training."""
    
    @patch.dict(os.environ, {'WORLD_SIZE': '1', 'RANK': '0'})
    @patch('torch.distributed.is_initialized', return_value=True)
    @patch('torch.distributed.get_world_size', return_value=1)
    @patch('torch.distributed.get_rank', return_value=0)
    @patch('torch.distributed.all_reduce')
    @patch('train.dist.get_rank', return_value=0)
    @patch('train.AsyncStructuredLogger')
    @patch('torch.cuda.reset_peak_memory_stats')
    @patch('torch.cuda.empty_cache')
    @patch('torch.cuda.max_memory_allocated', return_value=2e9)
    @patch('torch.distributed.barrier')
    def test_memory_tracking(self, mock_barrier, mock_max_mem, mock_empty_cache,
                            mock_reset_stats, mock_logger_cls, mock_dist_rank,
                            mock_all_reduce, mock_torch_rank, mock_world_size, mock_is_init):
        """Test memory tracking and management."""
        mock_logger = MagicMock()
        mock_logger_cls.return_value = mock_logger
        
        mock_model = MagicMock()
        mock_model.train = MagicMock()
        mock_param = MagicMock()
        mock_param.device = torch.device('cpu')
        mock_model.parameters = MagicMock(return_value=iter([mock_param]))
        output = MagicMock()
        output.loss = torch.tensor(2.5, requires_grad=True)
        mock_model.return_value = output
        
        mock_data_loader = MagicMock()
        mock_data_loader.__iter__ = lambda self: iter([[{
            'input_ids': torch.tensor([[1, 2]]),
            'labels': torch.tensor([[10, 20]]),
            'num_loss_counted_tokens': 2,
            'num_samples': 1,
            'batch_num_loss_counted_tokens': 2
        }]])
        
        with patch('train.take_gradient_step') as mock_grad_step:
            mock_grad_step.return_value = torch.tensor(1.0)
            
            with tempfile.TemporaryDirectory() as temp_dir:
                train(
                    model=mock_model,
                    optimizer=MagicMock(),
                    lr_scheduler=MagicMock(),
                    data_loader=mock_data_loader,
                    output_dir=temp_dir,
                    min_samples_per_checkpoint=100,
                    model_name_or_path="test/model"
                )
        
        # Verify memory management calls
        mock_reset_stats.assert_called()
        mock_empty_cache.assert_called()
        
        # Verify memory was tracked in metrics
        logged_metrics = mock_logger.log_sync.call_args[0][0]
        assert 'peak_memory_usage_GB' in logged_metrics
        assert logged_metrics['peak_memory_usage_GB'] == 2.0  # 2e9 / 1e9


if __name__ == "__main__":
    pytest.main([__file__, "-v"])
